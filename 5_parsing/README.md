# HH.ru parsing pipeline

Пайплайн обработки сырых данных HH.ru с резюме.  
Построен на паттерне «цепочка ответственности» и запускается командой:

```bash
python 5_parsing/app.py path/to/hh.csv
```

Рядом с исходным `hh.csv` создаются файлы:

- `x_data.npy` - матрица признаков (`float64`, без пропусков);
- `y_data.npy` - целевой вектор (`int64`).

## Что делает пайплайн

1. Загружает CSV, чистит текстовые артефакты и дубликаты.
2. Парсит из сырых колонок:
    - `Пол, возраст` -> `sex`, `age`;
    - `ЗП` -> `salary`, `currency`;
    - опыт работы -> `experience_years`;
    - `Образование и ВУЗ` -> `education_last_year`, `education_level`;
    - `Авто` -> `has_car`;
    - `Город` -> `city`, `relocation`, `business_trips`;
    - `График` -> нормализованный график работы;
    - должности -> `position`, `last_position`.

3. Кодирует признаки:
    - бинарные фичи: `sex`, `relocation`, `has_car` -> 0/1;
    - должности: `position`, `last_position` -> label encoding;
    - график: -> multi‑hot;
    - валюта и командировки: -> one‑hot;
    - образование: -> one‑hot.

4. Удаляет:
    - строки с `business_trips == "unknown"` и `education_level == "unknown"`;
    - сырые текстовые поля (`Пол, возраст`, `ЗП`, `Город`, `Образование и ВУЗ`, исходные должности и место работы);
    - все оставшиеся `object`/`string`‑колонки, кроме таргета.

5. Заполняет пропуски в числовых колонках медианой и приводит все признаки к
   числовому виду, чтобы датасет был готов к дальнейшему анализу.

### Warning
Небольшая часть строк удаляется в процессе очистки:
- дубликаты;
- записи с неопределенным уровнем образования;
- записи без информации о командировках.